{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf7b08c",
   "metadata": {},
   "source": [
    "# Task 2 — Data Preparation & Integration (Outcome-Oriented)\n",
    "\n",
    "**Input file:** `SA - Data for Task 2.xlsx`  \n",
    "Sheets: **Work Order Data** + **Repair Data**  \n",
    "Generated: **2025-12-16 06:33**\n",
    "\n",
    "## What this notebook delivers (business outcomes)\n",
    "- Identifies a reliable **Primary Key** for integration\n",
    "- Cleans both datasets so integration is **safe and auditable**\n",
    "- Produces a merged dataset that supports:\n",
    "  - cost & labor analytics\n",
    "  - failure vs fix correlation\n",
    "  - trend analysis (Task 3)\n",
    "\n",
    "> **Deliverable output:** `task2_merged_cleaned.xlsx` / `task2_merged_cleaned.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77851f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = r\"/mnt/data/SA - Data for Task 2.xlsx\"\n",
    "wo_raw = pd.read_excel(path, sheet_name=\"Work Order Data\")\n",
    "rp_raw = pd.read_excel(path, sheet_name=\"Repair Data\")\n",
    "print(\"Work Order shape:\", wo_raw.shape)\n",
    "print(\"Repair shape:\", rp_raw.shape)\n",
    "wo_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c11e9",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Primary Key identification\n",
    "**Why:** A wrong key creates wrong joins → wrong insights → wrong decisions.\n",
    "\n",
    "We evaluate candidates:\n",
    "- `Primary Key`\n",
    "- `Order No`\n",
    "- `Segment Number`\n",
    "- `Order No + Segment Number`\n",
    "\n",
    "**Outcome:** We choose the key with **lowest nulls**, **lowest duplicates**, and real-world interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a64634",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_stats = []\n",
    "for name, df in [(\"WorkOrder\", wo_raw), (\"Repair\", rp_raw)]:\n",
    "    for key in [\"Primary Key\", \"Order No\", \"Segment Number\", \"Order No + Segment Number\"]:\n",
    "        if key == \"Order No + Segment Number\":\n",
    "            combo = df[\"Order No\"].astype(str) + \"__\" + df[\"Segment Number\"].astype(str)\n",
    "            pk_stats.append({\n",
    "                \"dataset\": name,\n",
    "                \"key_candidate\": key,\n",
    "                \"rows\": len(df),\n",
    "                \"unique\": combo.nunique(dropna=True),\n",
    "                \"duplicates\": int(combo.duplicated().sum()),\n",
    "                \"nulls\": int((df[\"Order No\"].isna() | df[\"Segment Number\"].isna()).sum())\n",
    "            })\n",
    "        else:\n",
    "            pk_stats.append({\n",
    "                \"dataset\": name,\n",
    "                \"key_candidate\": key,\n",
    "                \"rows\": len(df),\n",
    "                \"unique\": df[key].nunique(dropna=True),\n",
    "                \"duplicates\": int(df[key].duplicated().sum()),\n",
    "                \"nulls\": int(df[key].isna().sum())\n",
    "            })\n",
    "pk_stats_df = pd.DataFrame(pk_stats)\n",
    "pk_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c04e98",
   "metadata": {},
   "source": [
    "### Decision\n",
    "If `Primary Key` is unique and non-null across both sheets, it is the best choice because:\n",
    "- it is designed for integration\n",
    "- it avoids edge cases where Order numbers repeat\n",
    "\n",
    "If not, we use the composite key `Order No + Segment Number`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple automatic decision\n",
    "use_primary_key = (\n",
    "    pk_stats_df.query(\"key_candidate=='Primary Key' and duplicates==0 and nulls==0\").shape[0] == 2\n",
    ")\n",
    "chosen_pk = \"Primary Key\" if use_primary_key else \"Order No + Segment Number\"\n",
    "print(\"Chosen key:\", chosen_pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e6863",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Data cleaning (both datasets)\n",
    "**Why:** Integration only works if both sides have consistent formats.\n",
    "\n",
    "Cleaning performed:\n",
    "- text normalization (trim, whitespace)\n",
    "- date parsing (`Order Date`, `Invoice Date`)\n",
    "- numeric coercion (`Qty`, `Revenue`, `Cost`, `Actual Hours`, etc.)\n",
    "- missing handling (categorical→`UNKNOWN`)\n",
    "- deduplication on chosen PK\n",
    "\n",
    "**Outcome:** Datasets become join-safe + analytics-safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(x):\n",
    "    if pd.isna(x): return \"\"\n",
    "    x = str(x).replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "    return re.sub(r\"\\s+\",\" \", x).strip()\n",
    "\n",
    "def coerce_numeric(series):\n",
    "    s = series.astype(str).str.replace(\",\", \"\", regex=False)\n",
    "    s = s.str.replace(\"$\",\"\", regex=False).str.strip()\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "wo = wo_raw.copy()\n",
    "rp = rp_raw.copy()\n",
    "\n",
    "for df in (wo, rp):\n",
    "    for c in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[c] = df[c].apply(normalize_text).replace(\"\", np.nan)\n",
    "\n",
    "wo[\"Order Date\"] = pd.to_datetime(wo[\"Order Date\"], errors=\"coerce\")\n",
    "rp[\"Invoice Date\"] = pd.to_datetime(rp[\"Invoice Date\"], errors=\"coerce\")\n",
    "\n",
    "for col in [\"Model Year\", \"Meter 1 Reading\"]:\n",
    "    if col in wo.columns:\n",
    "        wo[col] = coerce_numeric(wo[col])\n",
    "\n",
    "for col in [\"Qty\",\"Revenue\",\"Cost\",\"Actual Hours\",\"Segment Total $\"]:\n",
    "    if col in rp.columns:\n",
    "        rp[col] = coerce_numeric(rp[col])\n",
    "\n",
    "# fill categoricals\n",
    "for df in (wo, rp):\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].fillna(\"UNKNOWN\")\n",
    "\n",
    "# dedupe\n",
    "key_cols = [\"Primary Key\"] if chosen_pk==\"Primary Key\" else [\"Order No\",\"Segment Number\"]\n",
    "wo_before, rp_before = len(wo), len(rp)\n",
    "wo = wo.drop_duplicates(subset=key_cols, keep=\"first\")\n",
    "rp = rp.drop_duplicates(subset=key_cols, keep=\"first\")\n",
    "print(\"WO duplicates removed:\", wo_before - len(wo))\n",
    "print(\"RP duplicates removed:\", rp_before - len(rp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f76ca4",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Integration (Merge)\n",
    "**Join type selected:** **Left join** from Work Orders → Repair Data.\n",
    "\n",
    "**Why left join?**\n",
    "- Work order is the “master” business event (complaint/cause/correction)\n",
    "- Repair rows may be missing for some work orders (e.g., incomplete billing)\n",
    "- Left join preserves the full work order universe for analysis\n",
    "\n",
    "**Outcome:** A comprehensive dataset with both failure context and financial/labor details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_pk==\"Primary Key\":\n",
    "    merged = wo.merge(rp, on=\"Primary Key\", how=\"left\", suffixes=(\"_WO\",\"_RP\"))\n",
    "else:\n",
    "    merged = wo.merge(rp, on=[\"Order No\",\"Segment Number\"], how=\"left\", suffixes=(\"_WO\",\"_RP\"))\n",
    "\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d0a57",
   "metadata": {},
   "source": [
    "### Implications of other join types\n",
    "- **Inner join:** drops work orders with no matching repair records (risk: biased analysis)\n",
    "- **Right join:** not suitable because repair records without work order context are hard to interpret\n",
    "- **Full outer join:** keeps everything but requires more reconciliation (good for audits, not first-pass analytics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged outputs\n",
    "merged.to_excel(r\"/mnt/data/axionray_task2_3/task2_merged_cleaned.xlsx\", index=False)\n",
    "merged.to_csv(r\"/mnt/data/axionray_task2_3/task2_merged_cleaned.csv\", index=False)\n",
    "print(\"Saved:\", r\"/mnt/data/axionray_task2_3/task2_merged_cleaned.xlsx\")\n",
    "print(\"Saved:\", r\"/mnt/data/axionray_task2_3/task2_merged_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
